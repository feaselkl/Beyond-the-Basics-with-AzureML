{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deploy a simple ML pipeline for expense report estimation\r\n",
    "\r\n",
    "## Introduction\r\n",
    "In the prior tutorial, we saw how to train and register a model using Azure Machine Learning pipelines.  This tutorial shows how we can deploy the model to Azure Machine Learning.\r\n",
    "\r\n",
    "We will first deploy the results locally so that we can ensure that deployment succeeds.  Troubleshooting deployed models using only Azure Machine Learning's Studio is **very** difficult, but it can be a lot easier if you try to deploy locally, as then you can see the Docker logs and see what is happening."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.webservice import Webservice, LocalWebservice, AciWebservice\r\n",
    "from azureml.core.model import InferenceConfig\r\n",
    "from azureml.core.environment import Environment\r\n",
    "from azureml.core import Workspace\r\n",
    "from azureml.core.model import Model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploying the Model\r\n",
    "\r\n",
    "Our first step is to load the workspace where we deployed our model.  Then, we will load that model into the `model` object."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ws = Workspace.from_config()\r\n",
    "model = Model(ws, 'ExpenseReportsPipelineModel')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just as with model training, you have a few options for deciding on the environment you'd like to use.  In this case, we will once again use the training environment.  There is a separate inference environment which has less installed, but the downside to using the inference-only environment is that it does not have the Azure ML SDK pre-installed, so we'll go with what is technically a training image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `inference_config` object tells the REST API what, exactly, the specification should look like for the scoring endpoint.\r\n",
    "\r\n",
    "### Deploying the Model Locally\r\n",
    "\r\n",
    "The `deployment_config` here is a local web service which will run on port 6789.  Note that this does require that you have Docker installed and set up on your machine."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inference_config = InferenceConfig(entry_script=\"src/score.py\", environment=env)\r\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code deploys our pipeline-created expense reports model to our local deployment configuration.  The name of the deployment is `expense-reports-score-local` and we will be able to use it to perform local testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "local_service = Model.deploy(workspace=ws, \r\n",
    "                       name='expense-reports-score-local', \r\n",
    "                       models=[model], \r\n",
    "                       inference_config=inference_config, \r\n",
    "                       deployment_config = deployment_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wait for the deployment to complete and then paste out the URI that you'd need to call in order to score new expense reports."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "local_service.wait_for_deployment(show_output=True)\r\n",
    "print(f\"Scoring URI is : {local_service.scoring_uri}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deploying the Model via Azure Container Instance (ACI)\r\n",
    "\r\n",
    "Now that we've tested that the model works, we can deploy it via Azure Container Instances (ACI).  Note that Azure ML also supports deployment to Azure Kubernetes Service (AKS), and that AKS is much more production-ready than ACI.  You can safely use ACI for development and testing scenarios, but for production, Microsoft highly recommends AKS.\r\n",
    "\r\n",
    "In this case, we will declare that we want 1 CPU core and 2 GB of memory.  These are overkill for the service in question, but note that they are configurable based on your specific needs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aci_deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The deployment process looks almost exactly the same as above.  The only differences are the name of the deployment and the new deployment config.  This is nice because it intimates that you can use the same code to deploy different types of models to different locations, including even hosting on different platforms between development and production."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aci_service = Model.deploy(workspace=ws, \r\n",
    "                       name='expense-reports-score-aci', \r\n",
    "                       models=[model], \r\n",
    "                       inference_config=inference_config, \r\n",
    "                       deployment_config = aci_deployment_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we've wrapped everything up, print out the scoring URI.  This can take 5-10 minutes, so be patient at this step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aci_service.wait_for_deployment(show_output=True)\r\n",
    "print(f\"Scoring URI is : {aci_service.scoring_uri}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}